
<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="https://guestdaniel.github.io/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="https://guestdaniel.github.io/theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="https://guestdaniel.github.io/theme/font-awesome/css/font-awesome.min.css">





  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="index, follow" />


    <meta name="author" content="Daniel Guest" />
    <meta name="description" content="" />
<meta property="og:site_name" content="Daniel Guest"/>
<meta property="og:type" content="blog"/>
<meta property="og:title" content="Daniel Guest"/>
<meta property="og:description" content=""/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://guestdaniel.github.io"/>
<meta property="og:image" content="https://guestdaniel.github.io/images/profile.jpg">

  <title>Daniel Guest &ndash; Research</title>

</head>
<body>
  <aside>
    <div>
      <a href="https://guestdaniel.github.io">
        <img src="https://guestdaniel.github.io/images/profile.jpg" alt="Daniel Guest" title="Daniel Guest">
      </a>
      <h1><a href="https://guestdaniel.github.io">Daniel Guest</a></h1>

<p>PhD student<br>Department of Psychology<br>University of Minnesota</p>
      <nav>
        <ul class="list">
          <li><a href="https://guestdaniel.github.io/pages/about.html#about">About</a></li>
          <li><a href="https://guestdaniel.github.io/pages/cv.html#cv">CV</a></li>
          <li><a href="https://guestdaniel.github.io/#home">Home</a></li>
          <li><a href="https://guestdaniel.github.io/pages/research.html#research">Research</a></li>

        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-You can add links in your config file" href="#" target="_blank"><i class="fa fa-You can add links in your config file"></i></a></li>
        <li><a class="sc-Another social link" href="#" target="_blank"><i class="fa fa-Another social link"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>

    <nav>
      <a href="https://guestdaniel.github.io">    Home
</a>



    </nav>

<article class="single">
  <header>
    <h1 id="research">Research</h1>
  </header>
  <div>
    <h2><a href="http://apc.psych.umn.edu">UMN Auditory Perception and Cognition Lab</a></h2>
<p><strong>Time</strong>: September 2017 - present</p>
<p><strong>PI:</strong> Andrew Oxenham</p>
<p>I joined the Auditory Perception and Cognition Lab in September 2017. My research spans a variety of topics in psychacoustics and computational modeling of the auditory system:</p>
<ul>
<li>
<dl>
<dt><strong>Neural basis of pitch perception:</strong> One of my current projects focuses on examining pitch perception with harmonic complex tones composed entirely of high frequencies (i.e., &gt; 8 kHz). Previous research has demonstrated accurate pitch perception with such stimuli, and my present goal is to further investigate the neural code which mediates this pitch percept. To this end, I am investigating the ability of listeners to percieve pitch of high-frequency complex tone in the context of concurrent and spectrally-overlapping complex tone maskers. Additionally, I am developing computational models of neural responses to the stimuli used in these experiments in an effort to determine what part of the results (if any) can be accounted for on the basis of peripheral factors.</dt>
<dd><a href="https://guestdaniel.github.io/download/GuestOxenhamASA2020.pdf">Poster presented at ASA 2020 (virtual)</a></dd>
<dd><a href="https://guestdaniel.github.io/download/GuestOxenhamARO2020.pdf">Poster presented at ARO 2020</a></dd>
<dd><a href="https://guestdaniel.github.io/download/GuestOxenhamISAAR2019.pdf">Poster presented at ISAAR 2019</a></dd>
<dd><a href="https://guestdaniel.github.io/download/GuestOxenhamARO19.pdf">Poster presented at ARO 2019</a>    </dd>
</dl>
</li>
<li>
<dl>
<dt><strong>Role of pitch in the complex auditory scene:</strong> In my first project in the lab, I examined how F0 differences between a target talker and harmonic complex tone masker benefit speech segregation under a variety of conditions.</dt>
<dd><a href="https://guestdaniel.github.io/download/GuestOxenhamASAVictoria18.pdf">Poster presented at ASA Fall 2018</a> <br>
<a href="https://guestdaniel.github.io/download/GuestOxenhamSRD18.pdf">Poster presented at UMN CCS Spring Research Day 2018</a></dd>
</dl>
</li>
</ul>
<h2><a href="http://cvnlab.net/home.shtml">UMN Computational Visual Neuroscience Lab</a></h2>
<p><strong>Time</strong>: March 2019 - present</p>
<p><strong>PI:</strong> Kendrick Kay </p>
<p>As part of my <a href="http://catss.umn.edu/opportunities.htm">NSF-NRT Graduate Training Program in Sensory Science Fellowship</a>, I am currently participating in a rotation in the UMN Computational Visual Neuroscience Lab. For my rotation, I am working on implementation and analysis of visual encoding models in the human thalamus for a multi-session, multi-subject, high-resolution fMRI dataset currently being collected at the <a href="https://www.cmrr.umn.edu/">Center for Magnetic Resonance Research</a>. The project focuses in particular on characterizing how the pulvinar encodes features of natural images.</p>
<h2><a href="https://www.eriksholm.com/">Eriksholm Research Center</a></h2>
<p><strong>Time</strong>: May 2019 - August 2019 </p>
<p><strong>PI:</strong> Lars Bramsl√∏w</p>
<p>During the summer of 2019, I worked as a research intern at Oticon's Eriksholm Research Center. At Eriskholm, I researched tools and techniques for visualizing and interpreting deep neural networks designed to process and separate speech. </p>
<h2><a href="https://www.utdallas.edu/~assmann/">UT Dallas Speech Perception Lab</a></h2>
<p><strong>Time</strong>: May 2015 - May 2017 </p>
<p><strong>PI:</strong> Peter Assmann</p>
<dl>
<dt>As an undergraduate research assistant, my primary role was working on a project investigating perception of indexical properties in children's speech. Using stimuli from the North Texas Vowel Database modified by the <a href="www.wakayama-u.ac.jp/~kawahara/STRAIGHTadv/index_e.html">STRAIGHT vocoder</a>, I examined how listeners utilize fundamental frequency and formant frequencies when perceiving age and gender in children's speech. In particular, I focused on conditions of reduced spectrotemporal resolution (through the use of tone vocoders) and on differences between normal-hearing and cochlear-implant listeners. This research culminated in an honors thesis entitled "Perception of voice gender in children's speech".</dt>
<dd><a href="https://guestdaniel.github.io/download/GuestetalASA17.pdf">Poster presented at ASA Spring 2017</a> <br>
<a href="https://guestdaniel.github.io/download/GuestAEEUR17.pdf">Poster presented at UTD Undergraduate Poster Contest 2017</a> <br>
<a href="https://guestdaniel.github.io/download/GuestetalASA16.pdf">Poster presented at ASA Spring 2016</a></dd>
</dl>
  </div>
</article>

    <footer>
<p>&copy; Daniel Guest True</p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>





<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Daniel Guest ",
  "url" : "https://guestdaniel.github.io",
  "image": "https://guestdaniel.github.io/images/profile.jpg",
  "description": ""
}
</script>
</body>
</html>
